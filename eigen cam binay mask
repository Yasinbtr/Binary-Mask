import pathlib
from torch.nn import Conv2d
import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA # PCA için scikit-learn kütüphanesini içe aktaralım

# Sabit değerleri en üstte tanımlayalım
CONFIDENCE_THRESHOLD = 0.01
INPUT_SIZE = (416, 416)
OVERLAY_ALPHA = 0.6
BOX_COLOR = (0, 0, 0)  # RGB
TEXT_COLOR = (255, 255, 255)  # RGB
BOX_THICKNESS = 2
TEXT_SCALE = 0.5
TEXT_THICKNESS = 2

# YOLOv5 modelini yükle
model = torch.hub.load('/content/drive/MyDrive/deneme/yolov5', 'custom', path='/content/drive/MyDrive/deneme/best.pt', source='local')
model.eval()

# Modeldeki son Conv2D katmanını bul
def find_last_conv_layer(model):
    for layer in reversed(list(model.modules())):
        if isinstance(layer, Conv2d):
            return layer
    raise ValueError("Modelde Conv2D katmanı bulunamadı!")

target_layer = find_last_conv_layer(model.model)

# Eigen-CAM sınıfı
class EigenCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.activations = None
        self.hooks()

    def hooks(self):
        def forward_hook(module, input, output):
            self.activations = output.cpu().detach().numpy() # Aktivasyonları numpy dizisine dönüştür

        self.target_layer.register_forward_hook(forward_hook)

    def generate(self, input_tensor, box_idx=0):
        # Modelin ileri geçişi
        with torch.no_grad(): # Tahmin yaparken gradyan hesaplamasına gerek yok
            output = self.model(input_tensor)

        # Tahminleri işleme
        predictions = self.decode_predictions(output)

        # Tahminlerin varlığını kontrol et
        if len(predictions) == 0:
            raise ValueError("Model tarafından tahmin yapılmadı. Girdi görüntüsünü ve modeli kontrol edin.")

        # En yüksek güvene sahip kutuyu seç (veya istenen kutuyu)
        predictions = sorted(predictions, key=lambda x: x['confidence'], reverse=True)
        if box_idx >= len(predictions):
             print(f"Uyarı: İstenen kutu indeksi ({box_idx}) tahmin sayısından fazla. İlk kutu kullanılıyor.")
             target_box = predictions[0]
        else:
             target_box = predictions[box_idx]

        confidence_score = target_box['confidence_tensor']

        print(f"Kullanılan kutu: {target_box}")

        # Eigen-CAM hesaplama
        activations = self.activations # hooks tarafından numpy dizisi olarak alınır

        # Aktivasyonları düzleştir: (batch, channels, height, width) -> (batch, channels, height*width)
        # Daha sonra batch boyutunu kaldırıp (channels, height*width) haline getir
        activations_flat = activations.reshape(activations.shape[1], -1)

        # PCA uygula
        # Eigen-CAM için birinci ana bileşeni (principal component) kullanıyoruz
        pca = PCA(n_components=1)
        pca.fit(activations_flat.T) # PCA'yı (height*width, channels) üzerinde çalıştır
        principal_component = pca.components_[0] # shape (channels,)

        # Ana bileşeni ağırlık olarak kullan ve aktivasyonlarla çarp
        # Sonuç (channels, height*width) -> (height, width) CAM haritası olmalı
        # principal_component: (channels,)
        # activations_flat: (channels, height*width)
        # Eigen-CAM = principal_component (dot) activations_flat
        eigen_cam = np.dot(principal_component, activations_flat) # shape (height*width,)

        # CAM haritasını orijinal aktivasyon boyutlarına geri şekillendir (height, width)
        h, w = activations.shape[2], activations.shape[3]
        eigen_cam = eigen_cam.reshape(h, w)

        # Normalize et
        eigen_cam = (eigen_cam - eigen_cam.min()) / (eigen_cam.max() - eigen_cam.min() + 1e-9)

        return eigen_cam, predictions

    def generate_heatmap(self, img_rgb, eigen_cam):
        """Eigen-CAM ısı haritası oluştur ve görüntü üzerine bindir"""
        # Isı haritasını orijinal görüntü boyutlarına yeniden boyutlandır
        heatmap = cv2.resize(eigen_cam, (img_rgb.shape[1], img_rgb.shape[0]))

        # Isı haritasını 0-255 aralığına ölçeklendir ve uint8'e dönüştür
        heatmap = np.uint8(2 * heatmap)

        # Farklı bir renk haritası kullanalım (TURBO daha modern ve görsel olarak çekici)
        heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_TURBO)
        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)

        global max_deger
        max_deger = np.max(heatmap)
        min_deger = np.min(heatmap)
        max_deger = 0
        heatmap_colored[heatmap == max_deger] = [0, 0, 0]
        return heatmap_colored

        # İsteğe bağlı: En sıcak bölgeleri belirginleştirmek için eşikleme yapabilirsiniz
        # Bu örnekte direkt renk haritası kullanıyoruz.
        # heatmap_colored[heatmap < some_threshold] = [0,0, 0]  # Belirli bir eşiğin altındaki değerleri siyah yap

    @staticmethod
    def decode_predictions(output):
        """Ham tensor çıktısını okunabilir tahminlere dönüştür."""
        predictions = []
        # Output shape: (batch_size, num_predictions, 5 + num_classes)
        # YOLOv5 çıktısı genellikle (batch_size, num_bounding_boxes, 5+num_classes) şeklindedir.
        # 5: [center_x, center_y, width, height, confidence]
        # num_classes: Her sınıf için skorlar
        for i in range(output.shape[1]): # Her bir tahmini gez
            box_data = output[0, i, :] # İlk görüntüdeki i. tahminin tüm verisi
            box = box_data[:4].detach().cpu().numpy() # Kutu koordinatları
            confidence_tensor = box_data[4] # Güven skoru tensörü
            confidence = float(confidence_tensor.detach().cpu().numpy()) # Güven skoru float olarak
            # Sınıf skorları (eğer varsa) burada işlenebilir, şimdilik sadece güven skoruna odaklanıyoruz.

            if confidence > CONFIDENCE_THRESHOLD: # Tanımlanmış güven eşiğini kullan
                predictions.append({
                    'box': box,
                    'confidence': confidence,
                    'confidence_tensor': confidence_tensor # Orijinal tensörü de tutabiliriz
                })
        return predictions


def process_image(img_path, model, eigen_cam):
    """Görüntü işleme ve görselleştirme"""
    img = cv2.imread(img_path)
    if img is None:
        print(f"Hata: {img_path} dosyası okunamadı. Dosya yolunu kontrol edin.")
        return

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, INPUT_SIZE)

    # Tensor dönüşümü
    # Normalize etmeyi 0-1 aralığına çekelim (YOLOv5 genellikle 0-1 normalizasyonu kullanır)
    img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float().unsqueeze(0) / 255.0

    try:
        # Eigen-CAM hesaplama
        # Eigen-CAM generate metodu artık sadece input_tensor alıyor
        eigen_cam_result, predictions = eigen_cam.generate(img_tensor)

        # Isı haritası oluştur
        heatmap_colored = eigen_cam.generate_heatmap(img_rgb, eigen_cam_result)

        # Isı haritası bindirme
        # alpha değerlerini ısı haritası ve orijinal görüntü için ayarlayalım
        overlay = cv2.addWeighted(img_rgb, 1 - OVERLAY_ALPHA,
                                heatmap_colored, OVERLAY_ALPHA, 0)

        # Kutuları çiz (Eğer predictions varsa)
        final_image = overlay.copy() # Bindirilmiş görüntü üzerine çizeceğiz
        for p in predictions:
            # Kutu koordinatları (x_center, y_center, width, height) formatında olabilir
            # Bunları (x_min, y_min, x_max, y_max) formatına dönüştürmemiz gerekebilir
            # YOLO çıktısı genellikle bu formatta değildir, model çıktısını kontrol edin.
            # Eğer model çıktısı [cx, cy, w, h] ise:
            x_center, y_center, width, height = p['box']
            # Görüntü boyutlarına göre ölçeklendirme yap
            img_h, img_w = img_rgb.shape[0], img_rgb.shape[1]
            # Model INPUT_SIZE'a göre eğitilmiş olsa da, çıktı orijinal görüntüye göre ölçeklendirilmiş olabilir
            # Model çıktısının formatını ve ölçeklendirme şeklini kontrol edin.
            # Varsayılan olarak, model çıktısının orijinal görüntü boyutlarına göre ölçeklendirildiğini varsayalım
            x_min = int((x_center - width / 2) * img_w)
            y_min = int((y_center - height / 2) * img_h)
            x_max = int((x_center + width / 2) * img_w)
            y_max = int((y_center + height / 2) * img_h)



        # Sonucu kaydet
        output_path = "eigencam_result.jpg"
        final_image_bgr = cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(output_path, final_image_bgr)
        print(f"Eigen-CAM sonucu {output_path} dosyasına kaydedildi.")

        # Matplotlib ile görselleştirme
        plt.figure(figsize=(12, 8))
        plt.imshow(final_image)
        plt.title("Eigen-CAM Isı Haritası ve Tespitler", pad=20)
        plt.axis('off')
        plt.tight_layout()
        plt.show()

    except ValueError as e:
        print("Hata:", e)
    except Exception as e:
        print(f"Beklenmeyen Hata: {e}")


# Ana kod
if __name__ == "__main__":
    # Eigen-CAM hazırlığı
    target_layer = find_last_conv_layer(model.model)
    eigen_cam = EigenCAM(model.model, target_layer)

    # Görüntü işleme
    process_image('/content/drive/MyDrive/deneme/dota/optik/P2779.png', model, eigen_cam)
